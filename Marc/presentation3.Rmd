---
title: "NNET Presentation 3"
author: "Marc XU"
date: "1 mars 2019"
output:
  revealjs::revealjs_presentation:
    center: yes
    highlight: kate
    theme: league
    transition: zoom
---
# Neuron Network {data-background="pikachu.png"}

```{r message = FALSE}
library(neuralnet)
library(nnet)
library(mclust)
library(caret)
library(ROCR)
library(knitr)
library(e1071)
library(MLmetrics) # calcul de F1.Score
library(mltools) # calcul du coeff de correl. de Matthiew

knitr::opts_chunk$set(
  fig.width = 8, fig.height = 6, 
  fig.path = 'figures/iris_',
  fig.align = "center", 
  size = "tiny", 
  echo = FALSE, 
  eval = TRUE, 
  warning = FALSE, 
  message = FALSE, 
  results = TRUE, 
  comment = "")
```


```{r}
# Les fonctions

# La fonction accuracy
acc = function (resultats) {
  return(sum(diag(resultats)) / sum(resultats))
}

# La fonction erreur
err = function (resultats) {
  return(1 - (sum(diag(resultats)) / sum(resultats)))
}

# La fonction sensibilité
sens = function (resultats) {
  if (nrow(resultats) >= 2) {
    return(resultats[1,1] / (resultats[1,1] + resultats[2,1]))
  } else {
    return(NA)
  }
}

# La fonction spécifité
spec = function (resultats) {
  if (nrow(resultats) >= 2) {
    return(resultats[2,2] /(resultats[1,2] + resultats[2,2]))
  } else {
    return(NA)
  }
}

# La fonction F1_Score
scor = function (resultats) {
  return((2 * resultats[1,1]) / (2 * resultats[1,1] + resultats[1,2] + resultats[2,1]))
}

# La fonction ccm
ccm1 = function (resultats) {
  return((resultats[1,1] * resultats[2,2] - resultats[1,2] * resultats[2,1]) / (sqrt((resultats[1,1]+resultats[1,2]) * (resultats[1,1]+resultats[2,1]) * (resultats[2,2]+resultats[1,2]) *  (resultats[2,2]+resultats[2,1]))))
}
```

```{r}
table(iris$Species)
```
# Données IRIS

## Les données IRIS

```{r}
data("iris")
kable(head(iris))
```

## Résumés des données
```{r}
summary(iris)
```

## Visualisation des données (plot)
```{r}
plot(iris, col = iris$Species)
```

## Visualisation des données (boxplot)
```{r}
par(mfrow=c(2,2))
for (i in 1:4) {
  titre.boxplot <- paste("boxplot de :", colnames(iris)[i])
  boxplot(iris[,i] ~ iris[,5])
  title(titre.boxplot)
}
par(mfrow=c(1,1))
```

## Visualisation des données (histogramme)
```{r}
par(mfrow=c(4,3))
for (i in 1:4) {
  titre.histogramme <- paste("Histogramme de :", colnames(iris)[i])
  by(iris[,i], iris[,5], hist, main = titre.histogramme, breaks = 15, xlab = "cm")
}
par(mfrow=c(1,1))
```

```{r}
seto = as.numeric(iris$Species == "setosa")
versi = as.numeric(iris$Species == "versicolor")
virgi = as.numeric(iris$Species == "virginica")
```

```{r}
data.iris = data.frame(iris[,c(1:4)], seto, versi, virgi)
#data.seto = data.frame(iris[,c(1:4)], seto)
#data.versi = data.frame(iris[,c(1:4)], versi)
#data.virgi = data.frame(iris[,c(1:4)], virgi)
```

```{r}
set.seed(245)
formule = as.formula(seto + versi + virgi ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width)
reseau1 = neuralnet(formule, data = data.iris, hidden = c(1,1))
resultat_matrice1 <- as.data.frame(reseau1$result.matrix)
```

# Prediction
```{r}
set.seed(245)
ind.app <- sample(1:nrow(iris), 100)
iris.app <- iris[ind.app,]
iris.test <- iris[-ind.app,]
```

## Prédiction dans l'échantillon d'apprentissage
```{r, results = 'hide'}
set.seed(245)
iris.nn <- nnet::nnet(Species ~ ., data = iris, subset = ind.app, size = 1)
prediction = predict(iris.nn, newdata = iris.app, type = "class")
confiance <- table(prediction, iris.app$Species, dnn = c("predit", "observe"))
knitr::kable(confiance)
acc.app <- acc(confiance)
err.app <- err(confiance)
perf.app <- c(acc.app, err.app)
names(perf.app) <- c("accuracy", "erreur")
knitr::kable(perf.app)
```

## Prédiction Prédiction dans l'échantillon test
```{r, results = 'hide'}
set.seed(245)
prediction = predict(iris.nn, newdata = iris.test, type = "class")
confiance <- table(prediction, iris.test$Species, dnn = c("predit", "observe"))
knitr::kable(confiance)
acc.app <- acc(confiance)
err.app <- err(confiance)
perf.app <- c(acc.app, err.app)
names(perf.app) <- c("accuracy", "erreur")
knitr::kable(perf.app)
```

### Matrice de confusion
```{r}
matrice_confusion.ex = data.frame(CONDITION_POSITIVE = c("True Positive (TP)", "False Negative (FN)"), CONDITION_NEGATIVE = c("False Positive (FP)", "False Negative (TN)"), row.names = c("PREDICT_POSITIVE (P)","PREDICT_NEGATIVE (N)"))
kable(matrice_confusion.ex)

#predit = predict(iris.nn, newdata = iris.app)
predit = predict(iris.nn, newdata = iris)
observe = data.iris[,c(5:7)]

# La fonction pour la matrice de confusion
matrice_confusion = function (observation, prediction) {
  resultats1 = sapply(X = data.frame(observe = observation, predit = prediction),
                      FUN = round, digits=0)
  resultats.df = data.frame(resultats1)
  attach(resultats.df)
  table.resultat = table(
    observe = resultats.df$observe,
    prediction =  resultats.df$predit)
  return(table.resultat)
}
```

## Formule mathématiques (1)

Taux d'erreur (accuracy) : ACC = $\frac{TP+TN} {TP+TN+FP+TF}$

Sensibilité (sensibility) : TPR = $\frac{TP} {TP+FN}$

Specificité (specificity) : TNR = $\frac{TN} {TN+FP}$

## Formule mathématiques (2)

F1 score : F1 = $\frac{2*TP} {2*TP+FP+FN}$

Coefficient de corrélation de Matthews : MCC =  

$\frac{TP*TN-FP*FN} {((TP+FP)(TP+FN)(TN+FP)(TN+FN))^{-1}}$

# Le modèle SETOSA

## Le modèle SETOSA (1)

Matrice de confusion de l'espèce SETOSA
```{r}
kable(matrice_confusion(observe[,1], predit[,1]))

```

## Le modèle SETOSA (2)
```{r, eval = FALSE}
# Calculé directement par les fonctions de RStudio
matrice.setosa = confusionMatrix(table.resultat.seto)
acc.seto = matrice.setosa$overall["Accuracy"]
sen.seto = matrice.setosa$byClass["Sensitivity"]
spe.seto = matrice.setosa$byClass["Specificity"]
F1S_seto = F1_Score(resultats.df.seto$observe, resultats.df.seto$prediction, positive= NULL)
mcc.seto = mcc(actuals = resultats.df.seto$observe, preds = resultats.df.seto$prediction)
```

```{r, message = FALSE}
Paramètres = c("Taux bon", "Taux d'erreur","Sensibilité", "Specifité", "F1_Score", "Coeff. de cor. de Matthew")
Valeurs.seto = c(acc(matrice_confusion(observe[,1], predit[,1])),
                 err(matrice_confusion(observe[,1], predit[,1])),
                 sens(matrice_confusion(observe[,1], predit[,1])),
                 spec(matrice_confusion(observe[,1], predit[,1])),
                 scor(matrice_confusion(observe[,1], predit[,1])),
                 ccm1(matrice_confusion(observe[,1], predit[,1])))
kable(data.frame(Paramètres, Valeurs.seto))
```

# Le modèle VERSICOLOR

## Le modèle VERSICOLOR (1)

Matrice de confusion de l'espèce VERSICOLOR
```{r}
kable(matrice_confusion(observe[,2], predit[,2]))
```

## Le modèle VERSICOLOR (2)

```{r}
Valeurs.versi = c(acc(matrice_confusion(observe[,2], predit[,2])),
                  err(matrice_confusion(observe[,2], predit[,2])),
                  sens(matrice_confusion(observe[,2], predit[,2])),
                  spec(matrice_confusion(observe[,2], predit[,2])),
                  scor(matrice_confusion(observe[,2], predit[,2])),
                  ccm1(matrice_confusion(observe[,2], predit[,2])))
kable(data.frame(Paramètres, Valeurs.versi))
```

# Le modèle VIRGINICA

## Le modèle VIRGINICA (1)

Matrice de confusion de l'espèce VIRGINICA
```{r}
kable(matrice_confusion(observe[,3], predit[,3]))
```

## Le modèle VIRGINICA (2)

```{r}
Valeurs.virgi = c(acc(matrice_confusion(observe[,3], predit[,3])),
                  err(matrice_confusion(observe[,3], predit[,3])),
                  sens(matrice_confusion(observe[,3], predit[,3])),
                  spec(matrice_confusion(observe[,3], predit[,3])),
                  scor(matrice_confusion(observe[,3], predit[,3])),
                  ccm1(matrice_confusion(observe[,3], predit[,3])))
kable(data.frame(Paramètres, Valeurs.virgi)) 
```

# Courbe ROC

```{r}
prob = compute(reseau1, data.iris[, -c(5:7)])
prob.result = prob$net.result

aucfun = function(prob.result.entry, data.iris.entry) {
  pred = prediction(prob.result.entry, data.iris.entry)
  return(performance(pred, "auc")@y.values[[1]])
}
```

## Courbe ROC (1)

SETOSA  
```{r}
iris.app.prob.setosa <- iris.nn$fitted.values[, "setosa"]
iris.app.setosa <- iris.app$Species == "setosa"
seuil <- seq(0, 1, length.out = 100)
vsens <- rep(NA, 100)
vspe <- rep(NA, 100)
for (i in 1:100) {
  iris.pred <- iris.app.prob.setosa >= seuil[i]
  vsens[i] <- sens(table(iris.pred, iris.app.setosa))
  vspe[i] <- spec(table(iris.pred, iris.app.setosa))
}
plot(1-vspe, vsens, type = "l", col = "red",
     xlab = "FPR = 1-Spe", ylab = "TPR = Sens")
```

## Courbe ROC (2)

VERSICOLOR
```{r}
iris.app.prob.versicolor <- iris.nn$fitted.values[, "versicolor"]
iris.app.versicolor <- iris.app$Species == "versicolor"
seuil <- seq(0, 1, length.out = 100) # Seuil de taille 10 avec un pas (de 1 à taille)
vsens <- rep(NA, 100) # Pour les deux paramètres, création de deux vecteurs NA...
vspe <- rep(NA, 100) # ...(correspondant à la taille du seuil)
for (i in 1:100) {
  iris.pred.versicolor <- iris.app.prob.versicolor >= seuil[i]
  vsens[i] <- sens(table(iris.pred.versicolor, iris.app.versicolor))
  vspe[i] <- spec(table(iris.pred.versicolor, iris.app.versicolor))
}
plot(1-vspe, vsens, type = "l", col = "red", xlab = "FPR = 1-Spe", ylab = "TPR = Sens")

```

## Courbe ROC (3)

VIRGINICA
```{r}
iris.app.prob.virginica <- iris.nn$fitted.values[, "virginica"]
iris.app.virginica <- iris.app$Species == "virginica"
seuil <- seq(0, 1, length.out = 100) # Seuil de taille 10 avec un pas (de 1 à taille)
vsens <- rep(NA, 100) # Pour les deux paramètres, création de deux vecteurs NA...
vspe <- rep(NA, 100) # ...(correspondant à la taille du seuil)
for (i in 1:100) {
  iris.pred <- iris.app.prob.virginica >= seuil[i]
  vsens[i] <- sens(table(iris.pred, iris.app.virginica))
  vspe[i] <- spec(table(iris.pred, iris.app.virginica))
}
plot(1-vspe, vsens, type = "l", col = "red", xlab = "FPR = 1-Spe", ylab = "TPR = Sens")
```

## Valeurs AUC

```{r}
Auc = c("AUC setosa", "AUC versicolor", "AUC virginica")
Calcul_AUC = c(aucfun(prob.result[,1], data.iris$seto),
               aucfun(prob.result[,2], data.iris$versi),
               aucfun(prob.result[,3], data.iris$virgi))
kable(data.frame(Auc, Calcul_AUC))
```

## Recherche des paramètres optimaux

En laissant faire par la fonction `tune`
```{r nn.tune}
iris.nn.tune <- tune.nnet(Species ~ ., data = iris.app, validation.x = iris.val,
                     size = 1:4, sampling = "fix")
summary(iris.nn.tune)
best.iris.nn <- best.nnet(Species ~ ., data = iris.app, validation.x = iris.val, size = 1:4, sampling = "fix")
```
# Bibliographie

## Sites consultés
https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html (formules mathématiques)

