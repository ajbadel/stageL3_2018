# stageL3_2018
les données et le reste pour mes stagiaires de l'année 2018-2019, Marc Xu et Eric Son Dutt

## Créer un git
  
  - me donner leur login
  - et je les invite
    - fait pour Marc 'marcxu'
    - fait pour Eric 'Bibirani01'
  - sur vos machines, faire git clone "" du dossier dans son ensemble
  - dans vos répertoires respectifs, créez, avec un Rstudio, un projet ("xx.Rproj") ce sera votre projet principal de travail.
  - à partir de ce projet, créez autant de fichiers .Rmd (c'est à dire Rmarkdown, on oublie les fichiers scripts simples .R) que nécessaires
  
### Le git est créé, ca marche plus ou moins
  - alors que Git est installé sur les machines de l'UFR, Marc et Eric ne parviennent pas à le lancer.
  
## Apprendre le Markdown

- apparemment OK
- Marc et Eric ont commencé une présentation en reveal.json

## Le sujet
Etablir un modèle de prédiction de la clairance à partir de descripteurs géométriques et physico-chimiques de petits composés. Deux méthodes seront utilisées :

  - SVM
  - réseaux de neurones

## De la biblio

  - une référence dans le domaine dumachine learning (apprentissage supervisé) : [ESL](https://web.stanford.edu/~hastie/ElemStatLearn/index.html) par Hastie, Tibshirani & Friedman
  - un article sur les SVM : [SVM](https://towardsdatascience.com/demystifying-maths-of-svm-13ccfe00091e)
  - les SVM vu par Tanagra (en français) : [SVM](https://eric.univ-lyon2.fr/~ricco/tanagra/fichiers/fr_Tanagra_SVM_R_Python.pdf)
  
## Les données
Il y a trois fichiers :

  - le premier [data edragon](https://github.com/ajbadel/stageL3_2018/blob/master/data/placenta_edragon_91mol.csv) provient d'un logiciel libre, 
  	- c'est celui là que nous allons utiliser.
  - le second [data MOE](https://github.com/ajbadel/stageL3_2018/blob/master/data/placenta_MOE_2D_192.csv) provient d'un logiciel payant (cher), 
  	- nous n'allons donc pas l'utiliser. 
  - le fichier "propre" à utiliser pour faire les modèles [data](https://github.com/ajbadel/stageL3_2018/blob/master/data/placenta90.138.txt). Ce fichier a été créé à partir des deux précédents en :
    - enlevant l'individu abérrant
    - enlevant les descripteurs ayant des données manquantes
    - enlevant les descripteurs non ou peu variants, car non informatifs
    - enlevant les descripteurs trop corrélés entre eux
    - sélectionnant des descripteurs corrélés à la variable d'intéret, la clairance
  
Cependant, ce second fichier (MOE) contient une données très importante pour nous, la Clairance (CI).

### Etape 1 : réalisation d'un jeu de données "utilisable"

  - lire les deux jeux de données
    - vous avez lu des matrices ? des data.frames ? autre chose ?
  - vérifier que les noms des lignes sont les mêmes
    1. les noms des lignes doivent être les noms des composés étudiés
    2. vérifier que les composés sont bien dans le même ordre
    3. pourquoi est-ce important ?
  - récupérer la colonne "CI" du fichier MOE et l'ajouter au fichier edragon
  - faire un jeu de données d'étude
    - combien ce fichier a t'il de ligne ?
    - combien de colonnes ?
    - quels sont les entetes des lignes ?
      * si ce n'est pas le cas, donner le nom du composé
  
### Etape 2 : regarder les données

  - comment visualiser ces données ?
    - on laisse tomber pour l'instant
    - on fera plus tard, cf Etape 3
  
  - y a t'il des valeurs aberrantes ?
    - que faut-il en faire ? 
      - les garder ?
      - les enlever ? qu'est-ce que ca veut dire les enlever ?
        - enlever la ligne
        - enlever la colonne
        - remplacer la valeur aberrante par xx
  - ici, on ne peut regarder dans le détail que la clairance (`CI`)
    - faire histogramme et boxplot de `CI`
    - voir qu'un des composés a une valeur extreme (beaucoup plus élevée que les autres)
    - on enlève ce composé
 
  - y a t'il des données manquantes (999 dans le fichier) ?
    - comment traiter ces valeurs manquantes ?
    - remplacer "-999" par NA (`which(, arr.ind))
    - compter le nombre de NA par colonne (`apply` et `sum` et `is.na`)
      - on enlève les descripteurs ayant des données manquantes, quelque soit ce nombre (`na.omit`)
    - on vérifie qu'il n'y a plus de NA (ou de -999)
  
  - y a t'il des variables "constantes" (variance nulle) ?
    - si oui, on les enlève => 3 lignes de programme
    - calcul de la variance de toutes les colonnes (descripteurs) (`apply`)
    - ne garder que celles de variance non nulle (`which`)
    - on vérifie qu'il n'y a plus de constante
  - Au final, combien de lignes et de colonnes reste t-il ?

  
### Etape 3 : regarder les données  dans le sens "multivarié"

  - ACP, multidimensional scaling
  - classification (clustering), classification hiérarchique ascendante (`hclust`) et `kmeans`
  
### Etape 4 : faire des modèles

  - apprendre la méthode choisie (SVM ou NN) sur un jeu "facile", type iris de Fisher.
  - appliquer à nos données ...

## En parallèle : les iris de Fisher

### Comprendre ces données
cf programme de L2S5

### Appliquer NN ou SVM sur ces données

# Message du 11 mars

- Essayez de prendre le temps de regarder ce que j'ai fait par rapport à ce que vous avez fait (pareil, différents, intéressants dans l'un), nous aurons ainsi une vue assez complète du sujet.

- On peut alors passer à l'utilisation de ces méthodes sur le jeu de données.

- Pour vendredi 22 mars, une présentation chacun présentant
  - un résumé de la méthode choisie : je ne vous demande pas de me dire les formules mathématiques, mais d'essayer de m'expliquer ce qui se passe, les points + et -, les paramètres à optimiser
  - l'un de vous présente la table de confusion et le calcul du taux de bien prédits, la sensibilité et la spécificité et l'autre présente la courbe ROC.
  - l'application sur les données "iris"
  - un début d'application sur les données "membranes", si possible
j'ai réservé notre salle de réunion pour la présentation à partir de 14h.
