---
title: "SVM"
author: "Eric"
date: "8 février 2019"
<<<<<<< HEAD
output:
  revealjs::revealjs_presentation:
    center: yes
    highlight: kate
    theme: league
    transition: fade
  ioslides_presentation:
    highlight: kate

=======
output: ioslides_presentation
>>>>>>> 3a27b4ca210a4528d0e940c834d1dfba77ec97a0
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

<<<<<<< HEAD
```{r, eval=F}
install.packages("revealjs")
install.packages("caret")
install.packages("e1071")
install.packages("ggvis")
set.seed(1)
=======

```{r, eval = F}
install.packages("e1071")
>>>>>>> 3a27b4ca210a4528d0e940c834d1dfba77ec97a0
```

```{r}
library("revealjs")
#library("caret")
library("e1071")
#library ("ggvis")
```

```{r}
setwd(".")
data(iris)
```

```{r, eval = F}
summary(iris)
```


##Jeu de données

Les données que nous allons utiliser sont les mesures effectués sur les iris de Fisher.
Il y a **3** **especes** d'iris :

- Setosa
- Versicolor
- Virginica

La longueur et la largeur des pétales et sépales ont été mesurés sur 50 individus de chaque espèce.

##Visualisons graphiquement les données (data exploration)

##Répartition des individus selon la taille des sépales

```{r, comment="", fig.align = "center", fig.cap = "Plot"}
plot(iris$Sepal.Length, iris$Sepal.Width, col = iris$Species, xlab = "Longueur des sépales", ylab = "Largeur des sépales")
```

##Répartition des individus selon la taille des pétales

```{r, fig.align="center", fig.cap = "Plot"}
plot(iris$Petal.Length, iris$Petal.Width, col = iris$Species)
```

***
##Répartition des individus selon la taille des pétales et la taille des sépales (cmdscale)
```{r}
plot(cmdscale(dist(iris [,-5])), col= as.integer(iris[,5]))
```


***
On remarque que les individus d'une espece sont très differents des deux autres espèces.
<<<<<<< HEAD
Les setosas ont des tailles de pétales et de sépales très différentes par rapport aux autres espèces.

***
Notre but est de créer un modèle qui puisse déterminer à quelle espèce appartient l'individu testé grace aux donnée sur la taille des pétales et la taille des sépales.
Nous allons donc creer un **modèle test** qui sera optimisé grace à un **modèle d'apprentissage**

***
Voici un modèle test 
```{r, eval = F, fig.align="center"}
ech = sample(150,100)
column = c("Petal.Length", "Petal.Width", "Sepal.Length", "Sepal.Width", "Species")
iris1 = iris[ech,column]

modeltest = svm(Species ~., data = iris1, kernel = "linear", cost = 10, scale = F)

plot(modeltest, data = iris1,Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

***
Résumé du modele test:
```{r, eval = F}
summary(modeltest)
```

***
Voici un modèle d'apprentisage
```{r, fig.align = "center", comment = ""}
modelref = svm(Species~., data = iris, type = "C-classification", kernel = "polynomial", cost = 1, scale = F)

plot (modelref, data=iris, Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

***
Résumé du modèle de d'apprentissage:
```{r}
summary(modelref)
```

##Determination de la precision de prediction du modèle par observation d'une matrice de confusion (accuracy check)
***
Comparaisons des résultats de prediction du modèle avec les données actuelles
(Determination de la precision du modèle (accuracy check))

```{r, eval = F, fig.align= "center"}
pred = predict(modeltest, iris)
tab = table(predit = pred, observe = iris$Species)
tab
```

***
Comparaisons des résultats du modèle de référence avec les données observées
```{r}
pred2 = predict(modelref, iris)
tab = table(predit = pred2, observe = iris$Species)
tab
```

***
On remarque que les deux modèles font des erreurs de classifications. Même avec les données  C'est peut être dû au noyau qui est lineaire.
=======
Nous allons utiliser les données sur la taille des pétales (generation d'echantillons aleatoires)

```{r, eval = F}
ech = sample(150,100)
col = c("Petal.Length", "Petal.Width", "Species")
iris1 = iris[ech,col]
iris2 = iris[-ech,col]
```

```{r, fig.align= "center", eval = F}
svm1 = svm(Species ~., data = iris1, kernel = "linear", cost = .1, scale = F)
plot(svm1, iris1[,col])
```

***
Si on utilise les 4 variables aléatoires avec un kernel linéaire.

```{r, fig.align = "center", comment = ""}
model = svm(Species~., data = iris, kernel = "linear")
```

```{r, fig.align = "center"}
plot (model, data=iris, Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

Les croix correspondent aux vecteurs de soutient pour chaque classe

##Erreurs de classifications et prediction

On compare les predictions du modèle avec les données actuelles

```{r, fig.align= "center"}
pred = predict(model, iris)
tab = table(predit = pred, actuel = iris$Species)
tab
```

On remarque des erreurs de classification avec le model lineaire.
>>>>>>> 3a27b4ca210a4528d0e940c834d1dfba77ec97a0

##Tuning et optimisation du modèle

```{r, fig.align="center"}
<<<<<<< HEAD
set.seed(1)
model_t = tune(svm, Species~., data = iris, kernel = "polynomial", ranges= list(eps = seq(0,1,0.1), cost = 2^(1:5)))
```
 
```{r, fig.align= "center"}
=======
model_t = tune(svm, Species~., data = iris, ranges= list(eps = seq(0,1,0.1), cost = 2^(2:9)))
>>>>>>> 3a27b4ca210a4528d0e940c834d1dfba77ec97a0
plot (model_t)
```

##Le meilleur modèle

```{r}
mon_modele = model_t$best.model
summary (mon_modele)
```

