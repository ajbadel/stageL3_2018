---
title: "SVM"
author: "Eric"
date: "8 février 2019"
output:
  revealjs::revealjs_presentation:
    center: yes
    highlight: kate
    theme: league
    transition: fade
  ioslides_presentation:
    highlight: kate

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

```{r, eval=F}
install.packages("revealjs")
install.packages("caret")
install.packages("e1071")
install.packages("ggvis")
install.packages("ggplot2")
install.packages("GGally")
set.seed(1)
```

```{r, message = 'hide'}
library("revealjs")
#library("caret")
library("e1071")
#library ("ggvis")
library("GGally")
library("RColorBrewer")
library("ggplot2")
```

```{r fonctions}
tx.bon <- function(table) {
  return(sum(diag(table)) / sum(table))
}

tx.erreur <- function(table) {
  acc <- (sum(diag(table)) / sum(table))
  return(1 - acc)
}

sensibilite <- function(table) {
  if (nrow(table) >= 2) {
    return(table[1,1] / (table[1,1] + table[2,1]))
  } else {
    return(NA)
  }
}

specificite <- function(table) {
  if (nrow(table) >= 2) {
    return(table[2,2] / (table[2,2] + table[1,2]))
  } else {
    return(NA)
  }
}
```

```{r}
setwd(".")
data(iris)
```

##Jeu de données

Résumé des données
```{r, eval}
par(mfrow = c(1,2))
summary(iris)
head(iris)
```
***
Les données que nous allons utiliser sont les mesures effectués sur les iris de Fisher.
Il y a **3** **especes** d'iris :

- Setosa
- Versicolor
- Virginica

La longueur et la largeur des pétales et sépales ont été mesurés sur 50 individus de chaque espèce.

##Visualisons graphiquement les données (data exploration)
```{r, comment="", fig.align = "center", fig.cap = "Plot", eval = F}
plot(iris$Sepal.Length, iris$Sepal.Width, col = iris$Species, xlab = "Longueur des sépales", ylab = "Largeur des sépales")
```

```{r, fig.align="center", fig.cap = "Plot", eval = F}
plot(iris$Petal.Length, iris$Petal.Width, col = iris$Species)
``` 

***
Visualisation des données grâce à une remise à l'échelle des donnée.(MDS)
```{r, fig.align = "center"}
iris.cmd = cmdscale(dist(iris [,-5]))
plot(iris.cmd, col = iris$Species)
```

***
Visualisation des données grâce à une analyse des principaux composants
```{r, fig.align = "center"}
par(mfrow = c(1,2))
iris.acp <- prcomp(as.matrix(iris[,1:4]))
plot(iris.acp)
biplot(iris.acp)
```

***
- Le but de cet analyse est de réduire le nombre de variables à un nombre limité de combinaisons lineaires, ce sont les composantes
- On remarque sur la première figure que la 1ère composante possède plus de 98% des données. 
- Sur la 2ème figure, on remarque que "Petal Length" et Petal Width sont fortement correllés, cependant, "Sepal width" n'est pas du tout corréllé avec le reste des variables
- La longueur des fleches représente la taille des variables.

***
Visualisation globale des données
```{r, message = F}
par(mfrow=c(1,1))
GGally::ggpairs(iris, mapping = aes(color = Species))
```

***
- Representation de la densité de probabilité pour les 4 variables quantitatives en fonction des especes et d'un barplot pour la variables qualitative montrant le nombre d'individus dans chaque classe.
- Representation des plots de variables en fonction des autres
- Representation des histogrammes pour chaque espece en fonction de la variable
- Representation des boxplot des variables pour chaque espece
- Representation de la correlation entre les variables quantitatives

***
- On remarque que la variable "Sepal width" n'est pas corrélée avec les autres variables.
- On remarque également grâce aux histogrammes et boxplots que certains individus de l'espece setosas ont des tailles de pétales et de sépales très différentes par rapport aux autres espèces.

***
Notre but est de créer un modèle qui puisse déterminer à quelle espèce appartient l'individu testé grace aux donnée sur la taille des pétales et la taille des sépales.
Nous allons donc creer un **modèle test** qui sera optimisé grace à un **modèle d'apprentissage**

***
Voici un modèle test 
```{r, fig.align="center"}
set.seed (1000)
ech = sample(150,100)
column = c("Petal.Length", "Petal.Width", "Sepal.Length", "Sepal.Width", "Species")
iris1 = iris[ech,column]

modeltest = svm(Species ~., data = iris1, kernel = "linear", cost = 10, scale = F)

plot(modeltest, data = iris1,Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

***
Résumé du modele test:
```{r}
summary(modeltest)
```

***
Voici un modèle d'apprentisage
```{r, fig.align = "center", comment = ""}
modelref = svm(Species~., data = iris, type = "C-classification", kernel = "polynomial", cost = 1, scale = F)

plot (modelref, data=iris, Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

***
Résumé du modèle de d'apprentissage:
```{r}
summary(modelref)
```

##Determination de la precision de prediction du modèle par observation d'une matrice de confusion (accuracy check)
***
Comparaisons des résultats de prediction du modèle test avec les données observées
```{r, fig.align= "center"}
pred = predict(modeltest, iris)
tab = table(predit = pred, observe = iris$Species)
tab
acc.app.poly <- tx.bon(tab)
err.app.poly <- tx.erreur(tab)
perf.app.poly <- c(acc.app.poly, err.app.poly)
names(perf.app.poly) <- c("accuracy", "erreur")
knitr::kable(perf.app.poly)
```

***
Comparaisons des résultats de prédiction du modèle d'apprentissage avec les données observées
```{r}
pred2 = predict(modelref, iris)
tab2 = table(predit = pred2, observe = iris$Species)
tab2
acc.app.poly <- tx.bon(tab2)
err.app.poly <- tx.erreur(tab2)
perf.app.poly <- c(acc.app.poly, err.app.poly)
names(perf.app.poly) <- c("accuracy", "erreur")
knitr::kable(perf.app.poly)
```

***
On remarque que nos 2 modèles font très peu d'erreurs de classifications. 

##Tuning et optimisation du modèle

```{r, fig.align="center"}
set.seed(1)
model_t = tune(svm, Species~., data = iris, kernel = "polynomial", ranges= list(eps = seq(0,1,0.1), cost = 2^(1:5)))
```
 
```{r, fig.align= "center"}
plot (model_t)
```

```{r}
summary(model_t)
```

##Le meilleur modèle

```{r}
mon_modele = model_t$best.model
summary (mon_modele)
```