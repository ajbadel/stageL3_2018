---
title: "SVM"
author: "Eric"
date: "8 février 2019"
output:
  revealjs::revealjs_presentation:
    center: yes
    highlight: kate
    theme: league
    transition: fade
  ioslides_presentation:
    highlight: kate

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
```

```{r, eval=F}
install.packages("revealjs")
install.packages("caret")
install.packages("e1071")
install.packages("ggvis")
install.packages("ggplot2")
install.packages("GGally")
set.seed(1)
```

```{r, message = 'hide'}
library("revealjs")
#library("caret")
library("e1071")
#library ("ggvis")
library("GGally")
library("RColorBrewer")
library("ggplot2")
```

```{r fonctions}
tx.bon <- function(table) {
  return(sum(diag(table)) / sum(table))
}

tx.erreur <- function(table) {
  acc <- (sum(diag(table)) / sum(table))
  return(1 - acc)
}

sensibilite <- function(table) {
  if (nrow(table) >= 2) {
    return(table[1,1] / (table[1,1] + table[2,1]))
  } else {
    return(NA)
  }
}

specificite <- function(table) {
  if (nrow(table) >= 2) {
    return(table[2,2] / (table[2,2] + table[1,2]))
  } else {
    return(NA)
  }
}
```

```{r}
setwd(".")
data(iris)
```

##Jeu de données

Résumé des données
```{r, eval}
par(mfrow = c(1,2))
summary(iris)
head(iris)
```
***
Les données que nous allons utiliser sont les mesures effectués sur les iris de Fisher.
Il y a **3** **especes** d'iris :

- Setosa
- Versicolor
- Virginica

La longueur et la largeur des pétales et sépales ont été mesurés sur 50 individus de chaque espèce.

##Visualisons graphiquement les données (data exploration)
```{r, comment="", fig.align = "center", fig.cap = "Plot", eval = F}
plot(iris$Sepal.Length, iris$Sepal.Width, col = iris$Species, xlab = "Longueur des sépales", ylab = "Largeur des sépales")
```

```{r, fig.align="center", fig.cap = "Plot", eval = F}
plot(iris$Petal.Length, iris$Petal.Width, col = iris$Species)
``` 

***
Visualisation des données grâce à une remise à l'échelle des donnée.(MDS)
```{r, fig.align = "center"}
iris.cmd = cmdscale(dist(iris [,-5]))
plot(iris.cmd, col = iris$Species)
```

***
Visualisation des données grâce à une analyse des principaux composants
```{r, fig.align = "center"}
par(mfrow = c(1,2))
iris.acp <- prcomp(as.matrix(iris[,1:4]))
plot(iris.acp)
biplot(iris.acp)
```

***
- Le but de cet analyse est de réduire le nombre de variables à un nombre limité de combinaisons lineaires, ce sont les composantes
- On remarque sur la première figure que la 1ère composante possède plus de 98% des données. 
- Sur la 2ème figure, on remarque que "Petal Length" et Petal Width sont fortement correllés, cependant, "Sepal width" n'est pas du tout corréllé avec le reste des variables
- La longueur des fleches représente la taille des variables.

***
Visualisation globale des données
```{r, message = F}
par(mfrow=c(1,1))
GGally::ggpairs(iris, mapping = aes(color = Species))
```

***
- Representation de la densité de probabilité pour les 4 variables quantitatives en fonction des especes et d'un barplot pour la variables qualitative montrant le nombre d'individus dans chaque classe.
- Representation des plots de variables en fonction des autres
- Representation des histogrammes pour chaque espece en fonction de la variable
- Representation des boxplot des variables pour chaque espece
- Representation de la correlation entre les variables quantitatives

***
- On remarque que la variable "Sepal width" n'est pas corrélée avec les autres variables.
- On remarque également grâce aux histogrammes et boxplots que certains individus de l'espece setosas ont des tailles de pétales et de sépales très différentes par rapport aux autres espèces.

***
Notre but est de créer un modèle qui puisse déterminer à quelle espèce appartient l'individu testé grace aux donnée sur la taille des pétales et la taille des sépales.
Nous allons donc creer un **modèle test** qui sera optimisé grace à un **modèle d'apprentissage**

***
Verification du nombre d'individus dans notre échantillon d'apprentissage
```{r, fig.align="center"}
#faire 
set.seed (1000)

vIndApp = sample(1:dim(iris)[1],2*dim(iris)[1]/3)
matApp = iris[vIndApp,]
matApp_row = nrow(matApp)
names(matApp_row) = "individus dans échantillon d'apprentissage"
matApp_row
```
***
Verification du nombre d'individus dans notre échantillon test
```{r, fig.align = "center", comment = ""}
vIndTest = setdiff(1:nrow(iris),vIndApp)
matTest = iris[vIndTest,]
matTest_row = nrow(matTest)
names(matTest_row) = "individus dans notre échantillon test"
matTest_row
```

***
Verification de la répartition de d'individus dans nos échantillons (test d'homogénéité)
```{r, fig.align= "center"}
par(mfrow=c(1,2))
boxplot (matApp[,-5], las = 2)
boxplot (matTest[,-5], las = 2)
```

***
Voici les résultats obtenus le modele apprentissage
```{r, fig.align= "center"}
par(mfrow=c(2,1))
modelapp = svm(Species ~., data = matApp, type = "C-classification", kernel = "polynomial", cost = 1, scale = F)

plot(modelapp, data = matApp, Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

***
Voici les résultats obtenus le modele test
```{r, fig.align= "center"}
modeltest = svm(Species~., data = matTest, type = "C-classification", kernel = "polynomial", cost = 1, scale = F)

plot (modeltest, data=matTest, Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

***
Résumé du modèle de d'apprentissage:
```{r}
summary(modelapp)
```

***
Résumé du modèle test:
```{r}
summary(modeltest)
```

##Determination de la precision de prediction du modèle par observation d'une matrice de confusion (accuracy check)

***
Calcul des performances de prédiction de notre modèle d'apprentissage
```{r}
predapp = predict(modelapp, iris)
tabapp = table(predit = predapp, observe = iris$Species)
tabapp
```

```{r}
acc.app.poly <- tx.bon(tabapp)
err.app.poly <- tx.erreur(tabapp)
sens.app.poly = sensibilite(tabapp)
spec.app.poly = specificite(tabapp)
names(sens.app.poly) = "sensibilite du modele d'apprentissage"
sens.app.poly
names(spec.app.poly) = "specificite du modele d'apprentissage"
spec.app.poly
```

```{r, fig.align= "center"}
perf.app.poly <- c(acc.app.poly, err.app.poly)
names(perf.app.poly) <- c("accuracy", "error")
knitr::kable(perf.app.poly)
```

***
Calcul des performances de prédiction de notre modèle de test
```{r}
predtest = predict(modeltest, iris)
tabtest = table(predit = predtest, observe = iris$Species)
tabtest
```

```{r}
acc.test.poly <- tx.bon(tabtest)
err.test.poly <- tx.erreur(tabtest)
sens.test.poly = sensibilite(tabtest)
spec.test.poly = specificite(tabtest)
names(sens.test.poly) = "sensibilite du modele test"
sens.test.poly
names(spec.test.poly) = "specificite du modele test"
spec.test.poly
```

```{r}
perf.test.poly <- c(acc.test.poly, err.test.poly)
names(perf.test.poly) <- c("accuracy", "error")
knitr::kable(perf.test.poly)
```

***
On remarque que nos 2 modèles font très peu d'erreurs de classifications. 

##Tuning et optimisation du modèle

```{r, fig.align="center"}
set.seed(1)
model_t = tune(svm, Species~., data = iris, kernel = "polynomial", ranges= list(eps = seq(0,1,0.1), cost = 2^(1:5)))
```
 
```{r, fig.align= "center"}
plot (model_t)
```

```{r}
summary(model_t)
```

##Le meilleur modèle

```{r}
mon_modele = model_t$best.model
summary (mon_modele)
```