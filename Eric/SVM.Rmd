---
title: "SVM"
author: "Eric"
date: "8 février 2019"
output:
  revealjs::revealjs_presentation:
    center: yes
    highlight: kate
    theme: league
    transition: zoom
  ioslides_presentation:
    highlight: kate

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, eval=F}
install.packages("revealjs")
```

```{r}
library("revealjs")
```

```{r, eval = F}
install.packages("caret")
```

```{r}
library("caret")
```

```{r, eval = F}
install.packages("e1071")
set.seed(1)
```

```{r,}
library(e1071)
```

```{r}
setwd(".")
data(iris)
```

```{r, eval = F}
summary(iris)
```


##Jeu de données

Les données que nous allons utiliser sont les mesures effectués sur les iris de Fisher.
Il y a **3** **especes** d'iris :

- Setosa
- Versicolor
- Virginica

La longueur et la largeur des pétales et sépales ont été mesurés sur 50 individus de chaque espèce.

##Répartition des individus selon la taille des sépales

```{r, comment="", fig.align = "center", fig.cap = "Plot"}
plot(iris$Sepal.Length, iris$Sepal.Width, col = iris$Species)
```

##Répartition des individus selon la taille des pétales

```{r, fig.align="center", fig.cap = "Plot"}
plot(iris$Petal.Length, iris$Petal.Width, col = iris$Species)
```

***
On remarque que les individus d'une espece sont très differents des deux autres espèces.
Nous allons generer des données aléatoires à partir des données issus de la réalité.

***
Voici un modèle test généré à partir de donnée aléatoires issus des échantillons
```{r, eval}
ech = sample(150,100)
column = c("Petal.Length", "Petal.Width", "Sepal.Length", "Sepal.Width", "Species")
iris1 = iris[ech,column]
```

```{r, fig.align= "center"}
svm1 = svm(Species ~., data = iris1, kernel = "linear", cost = 10, scale = F)
#plot(cmdscale(dist(iris1 [,-5])), col= as.integer(iris1[,5]))
```

***
```{r}
plot(svm1, data = iris1,Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```

***
Résumé du modele test:
```{r}
summary(svm1)
```


```{r, fig.align = "center", comment = ""}
model = svm(Species~., data = iris, type = "C-classification", kernel = "linear", cost = .1, scale = F)
```

***
Voici un modèle de référence généré à partir de donnée issus des échantillions
```{r, fig.align = "center"}
plot (model, data=iris, Petal.Width~Petal.Length, slice = list(Sepal.Width = 3, Sepal.Length = 4))
```
Les croix correspondent aux vecteurs de soutient pour chaque classe
Ce sont les données qui se trouvent à la limite de la marge.

***
Résumé du modèle de référence:
```{r}
summary(model)
```

##Erreurs de classifications et prediction
***
Comparaisons des résultats de prediction du modèle avec les données actuelles

```{r, fig.align= "center"}
pred = predict(svm1, iris1)
pred
tab = table(predit = pred, observe = iris1$Species)
tab
```

***


***
Comparaisons des résultats du modèle de référence avec les données observées (Creation d'une matrice de confusion)
```{r}
pred2 = predict(model, iris)
tab = table(predit = pred2, observe = iris$Species)
tab
```

***
```{r}

```

***
On remarque que les deux modèles font des erreurs de classifications. Même avec les données  C'est peut être dû au noyau qui est lineaire.

##Tuning et optimisation de modèle

```{r, fig.align="center"}
set.seed(1)
model_t = tune(svm, Species~., data = iris, kernel = "linear", ranges= list(eps = seq(0,1,0.1), cost = 2^(1:5)))
```
 
```{r, fig.align= "center"}
plot (model_t)
```

```{r}
summary(model_t)
```

##Le meilleur modèle

```{r}
mon_modele = model_t$best.model
summary (mon_modele)
```